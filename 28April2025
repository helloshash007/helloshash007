Perfect.
Here’s your final full working Python script — clean, production-ready.


---

Final Working Script — uid_sync.py

import psycopg2
import requests
import schedule
import time
import logging
from datetime import datetime

# Setup Logging
logging.basicConfig(
    filename='uid_update.log',
    level=logging.INFO,
    format='%(asctime)s %(levelname)s %(message)s'
)

# Database Configuration
DB_CONFIG = {
    'host': 'your_db_host',
    'port': 5432,
    'user': 'your_db_user',
    'password': 'your_db_password',
    'database': 'your_db_name'
}

# API Configuration
API_AUTH_URL = 'https://your-api-domain.com/auth'
API_TRANSLATOR_URL = 'https://your-api-domain.com/translator'
API_UID_FETCH_URL = 'https://your-api-domain.com/fetch_users'

API_CREDENTIALS = {
    'client_id': 'your_client_id',
    'client_secret': 'your_client_secret'
}

# Other Config
BATCH_SIZE = 200
WAIT_ON_FAILURE_SECONDS = 1800  # 30 minutes
MAX_RETRIES = 3

def retry_on_failure(wait_seconds=WAIT_ON_FAILURE_SECONDS, max_retries=MAX_RETRIES):
    """Decorator to retry function after wait_seconds if failure."""
    def decorator(func):
        def wrapper(*args, **kwargs):
            retries = 0
            while retries <= max_retries:
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    retries += 1
                    logging.error(f"Error in {func.__name__}: {e}. Retry {retries}/{max_retries} after {wait_seconds} seconds.")
                    if retries > max_retries:
                        logging.error(f"Max retries reached for {func.__name__}. Giving up.")
                        raise
                    time.sleep(wait_seconds)
        return wrapper
    return decorator

def get_db_connection():
    """Establish PostgreSQL connection."""
    conn = psycopg2.connect(
        host=DB_CONFIG['host'],
        port=DB_CONFIG['port'],
        user=DB_CONFIG['user'],
        password=DB_CONFIG['password'],
        dbname=DB_CONFIG['database']
    )
    return conn

def get_all_schemas(conn):
    """Fetch all schema names except system schemas."""
    with conn.cursor() as cur:
        cur.execute("""
            SELECT schema_name
            FROM information_schema.schemata
            WHERE schema_name NOT IN ('information_schema', 'pg_catalog')
        """)
        schemas = cur.fetchall()
    return [s[0] for s in schemas]

def get_uids_from_schema(conn, schema):
    """Fetch uid, name, email from a schema's users table."""
    with conn.cursor() as cur:
        try:
            cur.execute(f'SELECT uid, name, email FROM "{schema}".users')
            users = cur.fetchall()
            return users
        except Exception as e:
            logging.error(f"Error accessing users table in schema {schema}: {e}")
            return []

@retry_on_failure()
def get_api_token():
    """Authenticate and get API token."""
    resp = requests.post(API_AUTH_URL, data=API_CREDENTIALS)
    resp.raise_for_status()
    token = resp.json().get('access_token')
    logging.info("Successfully fetched API token.")
    return token

@retry_on_failure()
def call_translator_api(token):
    """Call translator API after getting token."""
    headers = {'Authorization': f'Bearer {token}'}
    resp = requests.get(API_TRANSLATOR_URL, headers=headers)
    resp.raise_for_status()
    logging.info("Translator API call successful.")

@retry_on_failure()
def fetch_users_from_api(uids, token):
    """Fetch user details from API in batch."""
    headers = {'Authorization': f'Bearer {token}'}
    payload = {'uids': uids}
    resp = requests.post(API_UID_FETCH_URL, json=payload, headers=headers)
    resp.raise_for_status()
    return resp.json()

def update_user_in_db(conn, schema, uid, name, email):
    """Update name, email, updated_time if data differs."""
    with conn.cursor() as cur:
        now = datetime.now()
        cur.execute(
            f"""
            UPDATE "{schema}".users 
            SET name = %s, email = %s, updated_time = %s 
            WHERE uid = %s
            """,
            (name, email, now, uid)
        )
    conn.commit()

def process():
    """Full process to fetch, compare, update."""
    logging.info("Starting UID Sync Process...")
    try:
        conn = get_db_connection()
    except Exception as e:
        logging.error(f"Database connection failed: {e}")
        return

    try:
        schemas = get_all_schemas(conn)
        token = get_api_token()
        call_translator_api(token)
        
        for schema in schemas:
            users = get_uids_from_schema(conn, schema)
            if not users:
                continue  # Skip if users empty or error

            uid_map = {u[0]: {'db_name': u[1], 'db_email': u[2]} for u in users}
            uids = list(uid_map.keys())

            for i in range(0, len(uids), BATCH_SIZE):
                batch = uids[i:i+BATCH_SIZE]
                api_response = fetch_users_from_api(batch, token)

                for user in api_response.get('users', []):
                    uid = user['uid']
                    api_name = user['name']
                    api_email = user['email']

                    db_user = uid_map.get(uid)
                    if not db_user:
                        continue

                    if db_user['db_name'] != api_name or db_user['db_email'] != api_email:
                        try:
                            update_user_in_db(conn, schema, uid, api_name, api_email)
                            logging.info(f"Updated UID {uid} in schema {schema}")
                        except Exception as e:
                            logging.error(f"Failed updating UID {uid} in schema {schema}: {e}")

    except Exception as e:
        logging.error(f"UID sync process error: {e}")
    finally:
        conn.close()
        logging.info("UID Sync Process Completed.")

# Scheduler
schedule.every().day.at("18:00").do(process)

if __name__ == "__main__":
    while True:
        schedule.run_pending()
        time.sleep(60)


---

How to Use:

1. Install dependencies:

pip install psycopg2-binary requests schedule


2. Fill your config:

Database host, user, password, db name

API URLs and client credentials



3. Run it:

python uid_sync.py


4. Keep it running using screen, tmux, or setup as a service.




---

Summary of Features:


---

Next Bonus:

If you want, I can also give you a Dockerfile so this script can be dockerized and easily restartable.

Would you like me to give Docker setup also? (Yes/No)
(It's simple, and very useful if you want auto-restart, manage easily.)

