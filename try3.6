import psycopg2
import logging
import time
import subprocess
import psutil
import schedule
import requests
from datetime import datetime, timedelta
from reportlab.lib.pagesizes import letter
from reportlab.pdfgen import canvas
from threading import Thread

# Configure logging
logging.basicConfig(filename='replication_monitor.log', 
                    format='%(asctime)s %(levelname)s: %(message)s', 
                    level=logging.INFO)

DB_CONFIG = {
    'dbname': 'your_db_name',
    'user': 'your_db_user',
    'password': 'your_db_password',
    'host': 'your_db_host',
    'port': 'your_db_port'
}

# Confluence credentials
CONFLUENCE_BASE_URL = 'https://your_confluence_instance_url'
CONFLUENCE_PAGE_ID = 'your_page_id'
CONFLUENCE_USERNAME = 'your_username'
CONFLUENCE_PASSWORD = 'your_password'

# Dictionary to track confirmed_flush_lsn, recovery times, and copy.py executions per slot
slot_tracking = {}
copy_script_run_count = 0
max_copy_script_runs_per_day = 2
last_copy_run_time = None
copy_minimum_gap = timedelta(hours=6)  # Minimum 6-hour gap

# Reset the copy script run count daily
def reset_copy_script_run_count():
    global copy_script_run_count
    copy_script_run_count = 0
    logging.info("Resetting copy.py run count for the day")

# Check if copy.py is already running
def is_copy_script_running():
    for process in psutil.process_iter(['pid', 'name', 'cmdline']):
        if 'python' in process.info['name'] or 'python3' in process.info['name']:
            if 'copy.py' in process.info['cmdline']:
                logging.info(f"copy.py is already running with PID: {process.info['pid']}")
                return True
    return False

# Check if enough time has passed since the last execution
def can_run_copy_script():
    global last_copy_run_time
    if last_copy_run_time is None:
        return True
    time_since_last_run = datetime.now() - last_copy_run_time
    if time_since_last_run >= copy_minimum_gap:
        return True
    else:
        logging.info(f"Waiting for the 6-hour gap before running copy.py again. Last run was {time_since_last_run} ago.")
        return False

# Run the copy.py script in a non-blocking way
def run_copy_script():
    global copy_script_run_count, last_copy_run_time

    if copy_script_run_count >= max_copy_script_runs_per_day:
        logging.info(f"copy.py has already run {copy_script_run_count} times today, skipping execution.")
        return

    if not is_copy_script_running() and can_run_copy_script():
        try:
            # Run copy.py in a new thread to avoid blocking
            def run():
                logging.info("Starting copy.py in the background...")
                subprocess.Popen(['python3', 'copy.py'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
                logging.info("copy.py script started")
                global copy_script_run_count, last_copy_run_time
                copy_script_run_count += 1
                last_copy_run_time = datetime.now()  # Record the time when copy.py was last run

            Thread(target=run).start()

        except Exception as e:
            logging.error(f"Error running copy.py in the background: {str(e)}")
    else:
        logging.info("copy.py is already running or waiting for the 6-hour gap.")

# Monitor replication status
def get_replication_status():
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor()

        query = """
            SELECT slot_name, active, restart_lsn, confirmed_flush_lsn, 
            pg_size_pretty(pg_wal_lsn_diff(pg_current_wal_lsn(), confirmed_flush_lsn)) AS target_lag
            FROM pg_replication_slots 
            WHERE slot_type = 'logical'
        """
        cur.execute(query)
        replication_slots = cur.fetchall()

        if not replication_slots:
            logging.error("Check replication: No replication slots found")
            raise Exception("Check replication: No replication slots found")

        for slot in replication_slots:
            slot_name, active, restart_lsn, confirmed_flush_lsn, target_lag = slot
            log_replication_status(slot_name, active, confirmed_flush_lsn, target_lag)
        
        cur.close()
        conn.close()

    except Exception as e:
        logging.error(f"Error checking replication status: {str(e)}")

# Log the replication status and decide when to trigger copy.py
def log_replication_status(slot_name, active, confirmed_flush_lsn, target_lag):
    lag_value = parse_lag(target_lag)
    current_time = datetime.now()

    if not active:
        logging.error(f"Slot {slot_name} is inactive. Active flag is False")
    else:
        logging.info(f"Slot {slot_name} is active. Current confirmed_flush_lsn: {confirmed_flush_lsn}, Target lag: {target_lag}")

    # Log old and new confirmed_flush_lsn
    if slot_name in slot_tracking:
        previous_lsn = slot_tracking[slot_name]['confirmed_flush_lsn']
        if previous_lsn != confirmed_flush_lsn:
            logging.info(f"Slot {slot_name}: confirmed_flush_lsn changed from {previous_lsn} to {confirmed_flush_lsn}")
        slot_tracking[slot_name]['confirmed_flush_lsn'] = confirmed_flush_lsn
    else:
        slot_tracking[slot_name] = {'confirmed_flush_lsn': confirmed_flush_lsn, 'recovery_start_time': None, 'recovery_end_time': None}

    # Log when the lag starts recovering and when it fully recovers (lag == 0)
    if lag_value > 0:
        logging.warning(f"Slot {slot_name} target lag is not 0. Target lag: {target_lag}")

        if slot_tracking[slot_name]['recovery_start_time'] is None:
            slot_tracking[slot_name]['recovery_start_time'] = current_time
            logging.info(f"Slot {slot_name} recovery started at {current_time}")

    elif lag_value == 0:
        if slot_tracking[slot_name]['recovery_start_time'] is not None:
            slot_tracking[slot_name]['recovery_end_time'] = current_time
            recovery_duration = current_time - slot_tracking[slot_name]['recovery_start_time']
            logging.info(f"Slot {slot_name} target lag has recovered at {current_time}. Recovery took {recovery_duration}.")
            slot_tracking[slot_name]['recovery_start_time'] = None
            slot_tracking[slot_name]['recovery_end_time'] = None

    if lag_value > 150:
        logging.error(f"Slot {slot_name} lag exceeded 150MB. Running copy.py")
        run_copy_script()

def parse_lag(target_lag):
    if 'MB' in target_lag:
        return float(target_lag.replace('MB', ''))
    return 0

# Monitor replication without blocking other slots
def monitor_replication():
    logging.info("Starting replication status monitoring...")
    get_replication_status()

    # Check and compare confirmed_flush_lsn over two intervals
    time.sleep(60)
    get_replication_status()

# Generate a status report summarizing the log counts for the last 24 hours
def generate_status_report():
    logging.info("Generating status report for the last 24 hours...")
    error_count = 0
    warning_count = 0
    info_count = 0
    now = datetime.now()

    with open("replication_monitor.log", "r") as log_file:
        lines = log_file.readlines()
        for line in lines:
            timestamp_str = line.split(' ')[0]
            log_time = datetime.strptime(timestamp_str, "%Y-%m-%d %H:%M:%S")
            if now - log_time <= timedelta(hours=24):
                if 'ERROR' in line:
                    error_count += 1
                elif 'WARNING' in line:
                    warning_count += 1
                elif 'INFO' in line:
                    info_count += 1

    report = f"""
    Replication Monitoring Status Report (Last 24 Hours)
    ----------------------------------------------------
    Errors: {error_count}
    Warnings: {warning_count}
    Infos: {info_count}
    """

    logging.info(report)
    return report

# Upload the status report to Confluence
def upload_to_confluence(report):
    logging.info("Uploading report to Confluence...")
    url = f'{CONFLUENCE_BASE_URL}/rest/api/content/{CONFLUENCE_PAGE_ID}'
    
    headers = {
        'Content-Type': 'application/json',
    }
    
    # Construct the payload for Confluence
    data = {
        "version": {
            "number": get_current_confluence_version() + 1
        },
        "title": "Replication Monitoring Status Report",
        "type": "page",
        "body": {
            "storage": {
                "value": f"<p>{report.replace('\n', '<br/>')}</p>",
                "representation": "storage"
            }
        }
    }

    response = requests.put(
        url,
        json=data,
        auth=(CONFLUENCE_USERNAME, CONFLUENCE_PASSWORD),
        headers=headers
    )

    if response.status_code == 200:
        logging.info("Report successfully uploaded to Confluence.")
    else:
        logging.error(f"Failed to upload report to Confluence. Status code: {response.status_code}, Response: {response.text}")

# Helper function to get the current version of the Confluence page
def get_current_confluence_version():
    url = f'{CONFLUENCE_BASE_URL}/rest/api/content/{CONFLUENCE_PAGE_ID}'
    response = requests.get(url, auth=(CONFLUENCE_USERNAME, CONFLUENCE_PASSWORD))
    
    if response.status_code == 200:
        content = response.json()
        return content['version']['number']
    else:
        logging.error(f"Failed to fetch Confluence page version. Status code: {response.status_code}, Response: {response.text}")
        return 1  # Default to version 1 if something goes wrong

# Schedule tasks
def schedule_tasks():
    # Schedule replication monitoring every 10 minutes
    schedule.every(10).minutes.do(monitor_replication)
    
    # Reset copy.py run count at midnight
    schedule.every().day.at("00:00").do(reset_copy_script_run_count)

    # Schedule status report generation and upload every day at a specific time
    schedule.every().day.at("23:59").do(lambda: upload_to_confluence(generate_status_report()))

# Main loop to run scheduled tasks
def main():
    logging.info("Starting replication monitoring script...")

    # Schedule the monitoring tasks
    schedule_tasks()

    # Keep running the scheduled tasks
    while True:
        schedule.run_pending()
        time.sleep(1)

if __name__ == "__main__":
    main()